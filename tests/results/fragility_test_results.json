{
  "leaderboard_reference": {
    "source": "HuggingFace Open LLM Leaderboard",
    "score": 66.6
  },
  "sweep_results": {
    "metadata": {
      "model": "meta-llama/Meta-Llama-3-8B",
      "benchmark": "mmlu",
      "mode": "demo",
      "timestamp": "2026-02-13T00:47:11.480572+00:00",
      "architectures_tested": 5
    },
    "results": {
      "zero_shot": {
        "overall_accuracy": 0.6419,
        "subjects": {
          "stem": {
            "accuracy": 0.589,
            "tasks": 57,
            "details": {
              "abstract_algebra": {
                "accuracy": 0.5834,
                "correct": 75,
                "total": 129
              },
              "anatomy": {
                "accuracy": 0.6184,
                "correct": 61,
                "total": 100
              },
              "astronomy": {
                "accuracy": 0.6457,
                "correct": 69,
                "total": 107
              },
              "college_biology": {
                "accuracy": 0.6249,
                "correct": 98,
                "total": 157
              },
              "college_chemistry": {
                "accuracy": 0.6363,
                "correct": 101,
                "total": 160
              },
              "college_computer_science": {
                "accuracy": 0.5366,
                "correct": 67,
                "total": 126
              },
              "college_mathematics": {
                "accuracy": 0.5516,
                "correct": 102,
                "total": 186
              },
              "college_physics": {
                "accuracy": 0.6448,
                "correct": 56,
                "total": 88
              },
              "computer_security": {
                "accuracy": 0.539,
                "correct": 77,
                "total": 144
              },
              "conceptual_physics": {
                "accuracy": 0.5845,
                "correct": 47,
                "total": 82
              },
              "electrical_engineering": {
                "accuracy": 0.5521,
                "correct": 103,
                "total": 187
              },
              "elementary_mathematics": {
                "accuracy": 0.5672,
                "correct": 85,
                "total": 150
              },
              "high_school_biology": {
                "accuracy": 0.6383,
                "correct": 67,
                "total": 105
              },
              "high_school_chemistry": {
                "accuracy": 0.6032,
                "correct": 55,
                "total": 92
              },
              "high_school_computer_science": {
                "accuracy": 0.5604,
                "correct": 70,
                "total": 126
              },
              "high_school_mathematics": {
                "accuracy": 0.5481,
                "correct": 77,
                "total": 142
              },
              "high_school_physics": {
                "accuracy": 0.5756,
                "correct": 73,
                "total": 127
              },
              "high_school_statistics": {
                "accuracy": 0.5491,
                "correct": 55,
                "total": 101
              },
              "machine_learning": {
                "accuracy": 0.6484,
                "correct": 97,
                "total": 150
              }
            }
          },
          "humanities": {
            "accuracy": 0.6732,
            "tasks": 52,
            "details": {
              "formal_logic": {
                "accuracy": 0.6315,
                "correct": 108,
                "total": 172
              },
              "high_school_european_history": {
                "accuracy": 0.7241,
                "correct": 97,
                "total": 135
              },
              "high_school_us_history": {
                "accuracy": 0.7052,
                "correct": 110,
                "total": 157
              },
              "high_school_world_history": {
                "accuracy": 0.6247,
                "correct": 66,
                "total": 106
              },
              "international_law": {
                "accuracy": 0.7245,
                "correct": 68,
                "total": 95
              },
              "jurisprudence": {
                "accuracy": 0.6508,
                "correct": 89,
                "total": 137
              },
              "logical_fallacies": {
                "accuracy": 0.6378,
                "correct": 116,
                "total": 182
              },
              "moral_disputes": {
                "accuracy": 0.6281,
                "correct": 89,
                "total": 143
              },
              "moral_scenarios": {
                "accuracy": 0.7175,
                "correct": 112,
                "total": 157
              },
              "philosophy": {
                "accuracy": 0.6531,
                "correct": 58,
                "total": 89
              },
              "prehistory": {
                "accuracy": 0.7299,
                "correct": 109,
                "total": 150
              },
              "professional_law": {
                "accuracy": 0.6693,
                "correct": 62,
                "total": 94
              },
              "world_religions": {
                "accuracy": 0.7256,
                "correct": 98,
                "total": 136
              }
            }
          },
          "social_sciences": {
            "accuracy": 0.6941,
            "tasks": 48,
            "details": {
              "econometrics": {
                "accuracy": 0.6781,
                "correct": 71,
                "total": 106
              },
              "high_school_geography": {
                "accuracy": 0.6595,
                "correct": 87,
                "total": 133
              },
              "high_school_government_and_politics": {
                "accuracy": 0.7133,
                "correct": 75,
                "total": 106
              },
              "high_school_macroeconomics": {
                "accuracy": 0.6636,
                "correct": 102,
                "total": 154
              },
              "high_school_microeconomics": {
                "accuracy": 0.7496,
                "correct": 65,
                "total": 87
              },
              "high_school_psychology": {
                "accuracy": 0.6666,
                "correct": 125,
                "total": 189
              },
              "human_sexuality": {
                "accuracy": 0.6426,
                "correct": 95,
                "total": 148
              },
              "professional_psychology": {
                "accuracy": 0.7253,
                "correct": 134,
                "total": 185
              },
              "public_relations": {
                "accuracy": 0.6902,
                "correct": 98,
                "total": 143
              },
              "security_studies": {
                "accuracy": 0.6826,
                "correct": 124,
                "total": 182
              },
              "sociology": {
                "accuracy": 0.6374,
                "correct": 97,
                "total": 153
              },
              "us_foreign_policy": {
                "accuracy": 0.7055,
                "correct": 83,
                "total": 119
              }
            }
          },
          "other": {
            "accuracy": 0.616,
            "tasks": 43,
            "details": {
              "business_ethics": {
                "accuracy": 0.5975,
                "correct": 95,
                "total": 160
              },
              "clinical_knowledge": {
                "accuracy": 0.6665,
                "correct": 125,
                "total": 189
              },
              "college_medicine": {
                "accuracy": 0.6549,
                "correct": 117,
                "total": 180
              },
              "global_facts": {
                "accuracy": 0.6133,
                "correct": 101,
                "total": 166
              },
              "human_aging": {
                "accuracy": 0.5753,
                "correct": 94,
                "total": 164
              },
              "management": {
                "accuracy": 0.5626,
                "correct": 77,
                "total": 137
              },
              "marketing": {
                "accuracy": 0.5935,
                "correct": 83,
                "total": 141
              },
              "medical_genetics": {
                "accuracy": 0.6571,
                "correct": 53,
                "total": 81
              },
              "miscellaneous": {
                "accuracy": 0.6406,
                "correct": 87,
                "total": 137
              },
              "nutrition": {
                "accuracy": 0.559,
                "correct": 109,
                "total": 196
              },
              "professional_accounting": {
                "accuracy": 0.5975,
                "correct": 97,
                "total": 163
              },
              "professional_medicine": {
                "accuracy": 0.6227,
                "correct": 55,
                "total": 89
              },
              "virology": {
                "accuracy": 0.6576,
                "correct": 111,
                "total": 169
              }
            }
          }
        }
      },
      "chain_of_thought": {
        "overall_accuracy": 0.7181,
        "subjects": {
          "stem": {
            "accuracy": 0.6931,
            "tasks": 57,
            "details": {
              "abstract_algebra": {
                "accuracy": 0.7491,
                "correct": 96,
                "total": 129
              },
              "anatomy": {
                "accuracy": 0.6971,
                "correct": 69,
                "total": 100
              },
              "astronomy": {
                "accuracy": 0.6756,
                "correct": 72,
                "total": 107
              },
              "college_biology": {
                "accuracy": 0.6411,
                "correct": 100,
                "total": 157
              },
              "college_chemistry": {
                "accuracy": 0.6697,
                "correct": 107,
                "total": 160
              },
              "college_computer_science": {
                "accuracy": 0.7016,
                "correct": 88,
                "total": 126
              },
              "college_mathematics": {
                "accuracy": 0.6712,
                "correct": 124,
                "total": 186
              },
              "college_physics": {
                "accuracy": 0.7059,
                "correct": 62,
                "total": 88
              },
              "computer_security": {
                "accuracy": 0.7287,
                "correct": 104,
                "total": 144
              },
              "conceptual_physics": {
                "accuracy": 0.6459,
                "correct": 52,
                "total": 82
              },
              "electrical_engineering": {
                "accuracy": 0.7433,
                "correct": 138,
                "total": 187
              },
              "elementary_mathematics": {
                "accuracy": 0.7169,
                "correct": 107,
                "total": 150
              },
              "high_school_biology": {
                "accuracy": 0.693,
                "correct": 72,
                "total": 105
              },
              "high_school_chemistry": {
                "accuracy": 0.6918,
                "correct": 63,
                "total": 92
              },
              "high_school_computer_science": {
                "accuracy": 0.7395,
                "correct": 93,
                "total": 126
              },
              "high_school_mathematics": {
                "accuracy": 0.6745,
                "correct": 95,
                "total": 142
              },
              "high_school_physics": {
                "accuracy": 0.6865,
                "correct": 87,
                "total": 127
              },
              "high_school_statistics": {
                "accuracy": 0.7387,
                "correct": 74,
                "total": 101
              },
              "machine_learning": {
                "accuracy": 0.6819,
                "correct": 102,
                "total": 150
              }
            }
          },
          "humanities": {
            "accuracy": 0.7271,
            "tasks": 52,
            "details": {
              "formal_logic": {
                "accuracy": 0.6982,
                "correct": 120,
                "total": 172
              },
              "high_school_european_history": {
                "accuracy": 0.7284,
                "correct": 98,
                "total": 135
              },
              "high_school_us_history": {
                "accuracy": 0.7454,
                "correct": 117,
                "total": 157
              },
              "high_school_world_history": {
                "accuracy": 0.6833,
                "correct": 72,
                "total": 106
              },
              "international_law": {
                "accuracy": 0.6892,
                "correct": 65,
                "total": 95
              },
              "jurisprudence": {
                "accuracy": 0.7395,
                "correct": 101,
                "total": 137
              },
              "logical_fallacies": {
                "accuracy": 0.7154,
                "correct": 130,
                "total": 182
              },
              "moral_disputes": {
                "accuracy": 0.7338,
                "correct": 104,
                "total": 143
              },
              "moral_scenarios": {
                "accuracy": 0.7386,
                "correct": 115,
                "total": 157
              },
              "philosophy": {
                "accuracy": 0.7478,
                "correct": 66,
                "total": 89
              },
              "prehistory": {
                "accuracy": 0.6742,
                "correct": 101,
                "total": 150
              },
              "professional_law": {
                "accuracy": 0.7018,
                "correct": 65,
                "total": 94
              },
              "world_religions": {
                "accuracy": 0.7552,
                "correct": 102,
                "total": 136
              }
            }
          },
          "social_sciences": {
            "accuracy": 0.7441,
            "tasks": 48,
            "details": {
              "econometrics": {
                "accuracy": 0.7951,
                "correct": 84,
                "total": 106
              },
              "high_school_geography": {
                "accuracy": 0.689,
                "correct": 91,
                "total": 133
              },
              "high_school_government_and_politics": {
                "accuracy": 0.7803,
                "correct": 82,
                "total": 106
              },
              "high_school_macroeconomics": {
                "accuracy": 0.7972,
                "correct": 122,
                "total": 154
              },
              "high_school_microeconomics": {
                "accuracy": 0.803,
                "correct": 69,
                "total": 87
              },
              "high_school_psychology": {
                "accuracy": 0.6973,
                "correct": 131,
                "total": 189
              },
              "human_sexuality": {
                "accuracy": 0.7354,
                "correct": 108,
                "total": 148
              },
              "professional_psychology": {
                "accuracy": 0.7684,
                "correct": 142,
                "total": 185
              },
              "public_relations": {
                "accuracy": 0.7411,
                "correct": 105,
                "total": 143
              },
              "security_studies": {
                "accuracy": 0.7959,
                "correct": 144,
                "total": 182
              },
              "sociology": {
                "accuracy": 0.685,
                "correct": 104,
                "total": 153
              },
              "us_foreign_policy": {
                "accuracy": 0.7499,
                "correct": 89,
                "total": 119
              }
            }
          },
          "other": {
            "accuracy": 0.7112,
            "tasks": 43,
            "details": {
              "business_ethics": {
                "accuracy": 0.7543,
                "correct": 120,
                "total": 160
              },
              "clinical_knowledge": {
                "accuracy": 0.735,
                "correct": 138,
                "total": 189
              },
              "college_medicine": {
                "accuracy": 0.6751,
                "correct": 121,
                "total": 180
              },
              "global_facts": {
                "accuracy": 0.6734,
                "correct": 111,
                "total": 166
              },
              "human_aging": {
                "accuracy": 0.6888,
                "correct": 112,
                "total": 164
              },
              "management": {
                "accuracy": 0.659,
                "correct": 90,
                "total": 137
              },
              "marketing": {
                "accuracy": 0.6878,
                "correct": 96,
                "total": 141
              },
              "medical_genetics": {
                "accuracy": 0.6862,
                "correct": 55,
                "total": 81
              },
              "miscellaneous": {
                "accuracy": 0.771,
                "correct": 105,
                "total": 137
              },
              "nutrition": {
                "accuracy": 0.7279,
                "correct": 142,
                "total": 196
              },
              "professional_accounting": {
                "accuracy": 0.7468,
                "correct": 121,
                "total": 163
              },
              "professional_medicine": {
                "accuracy": 0.6803,
                "correct": 60,
                "total": 89
              },
              "virology": {
                "accuracy": 0.6627,
                "correct": 111,
                "total": 169
              }
            }
          }
        }
      },
      "persona_based": {
        "overall_accuracy": 0.6703,
        "subjects": {
          "stem": {
            "accuracy": 0.6468,
            "tasks": 57,
            "details": {
              "abstract_algebra": {
                "accuracy": 0.6404,
                "correct": 82,
                "total": 129
              },
              "anatomy": {
                "accuracy": 0.6126,
                "correct": 61,
                "total": 100
              },
              "astronomy": {
                "accuracy": 0.6763,
                "correct": 72,
                "total": 107
              },
              "college_biology": {
                "accuracy": 0.5921,
                "correct": 92,
                "total": 157
              },
              "college_chemistry": {
                "accuracy": 0.6018,
                "correct": 96,
                "total": 160
              },
              "college_computer_science": {
                "accuracy": 0.6383,
                "correct": 80,
                "total": 126
              },
              "college_mathematics": {
                "accuracy": 0.6999,
                "correct": 130,
                "total": 186
              },
              "college_physics": {
                "accuracy": 0.5999,
                "correct": 52,
                "total": 88
              },
              "computer_security": {
                "accuracy": 0.6024,
                "correct": 86,
                "total": 144
              },
              "conceptual_physics": {
                "accuracy": 0.6086,
                "correct": 49,
                "total": 82
              },
              "electrical_engineering": {
                "accuracy": 0.6195,
                "correct": 115,
                "total": 187
              },
              "elementary_mathematics": {
                "accuracy": 0.6876,
                "correct": 103,
                "total": 150
              },
              "high_school_biology": {
                "accuracy": 0.6182,
                "correct": 64,
                "total": 105
              },
              "high_school_chemistry": {
                "accuracy": 0.6334,
                "correct": 58,
                "total": 92
              },
              "high_school_computer_science": {
                "accuracy": 0.6383,
                "correct": 80,
                "total": 126
              },
              "high_school_mathematics": {
                "accuracy": 0.5979,
                "correct": 84,
                "total": 142
              },
              "high_school_physics": {
                "accuracy": 0.6837,
                "correct": 86,
                "total": 127
              },
              "high_school_statistics": {
                "accuracy": 0.6378,
                "correct": 64,
                "total": 101
              },
              "machine_learning": {
                "accuracy": 0.6521,
                "correct": 97,
                "total": 150
              }
            }
          },
          "humanities": {
            "accuracy": 0.6971,
            "tasks": 52,
            "details": {
              "formal_logic": {
                "accuracy": 0.7485,
                "correct": 128,
                "total": 172
              },
              "high_school_european_history": {
                "accuracy": 0.7339,
                "correct": 99,
                "total": 135
              },
              "high_school_us_history": {
                "accuracy": 0.6378,
                "correct": 100,
                "total": 157
              },
              "high_school_world_history": {
                "accuracy": 0.6662,
                "correct": 70,
                "total": 106
              },
              "international_law": {
                "accuracy": 0.7409,
                "correct": 70,
                "total": 95
              },
              "jurisprudence": {
                "accuracy": 0.7252,
                "correct": 99,
                "total": 137
              },
              "logical_fallacies": {
                "accuracy": 0.6663,
                "correct": 121,
                "total": 182
              },
              "moral_disputes": {
                "accuracy": 0.64,
                "correct": 91,
                "total": 143
              },
              "moral_scenarios": {
                "accuracy": 0.738,
                "correct": 115,
                "total": 157
              },
              "philosophy": {
                "accuracy": 0.6996,
                "correct": 62,
                "total": 89
              },
              "prehistory": {
                "accuracy": 0.6956,
                "correct": 104,
                "total": 150
              },
              "professional_law": {
                "accuracy": 0.7342,
                "correct": 69,
                "total": 94
              },
              "world_religions": {
                "accuracy": 0.6467,
                "correct": 87,
                "total": 136
              }
            }
          },
          "social_sciences": {
            "accuracy": 0.6884,
            "tasks": 48,
            "details": {
              "econometrics": {
                "accuracy": 0.6326,
                "correct": 67,
                "total": 106
              },
              "high_school_geography": {
                "accuracy": 0.6852,
                "correct": 91,
                "total": 133
              },
              "high_school_government_and_politics": {
                "accuracy": 0.7012,
                "correct": 74,
                "total": 106
              },
              "high_school_macroeconomics": {
                "accuracy": 0.7015,
                "correct": 108,
                "total": 154
              },
              "high_school_microeconomics": {
                "accuracy": 0.6519,
                "correct": 56,
                "total": 87
              },
              "high_school_psychology": {
                "accuracy": 0.7396,
                "correct": 139,
                "total": 189
              },
              "human_sexuality": {
                "accuracy": 0.7379,
                "correct": 109,
                "total": 148
              },
              "professional_psychology": {
                "accuracy": 0.6646,
                "correct": 122,
                "total": 185
              },
              "public_relations": {
                "accuracy": 0.7306,
                "correct": 104,
                "total": 143
              },
              "security_studies": {
                "accuracy": 0.6619,
                "correct": 120,
                "total": 182
              },
              "sociology": {
                "accuracy": 0.6292,
                "correct": 96,
                "total": 153
              },
              "us_foreign_policy": {
                "accuracy": 0.6495,
                "correct": 77,
                "total": 119
              }
            }
          },
          "other": {
            "accuracy": 0.6488,
            "tasks": 43,
            "details": {
              "business_ethics": {
                "accuracy": 0.6549,
                "correct": 104,
                "total": 160
              },
              "clinical_knowledge": {
                "accuracy": 0.6415,
                "correct": 121,
                "total": 189
              },
              "college_medicine": {
                "accuracy": 0.6097,
                "correct": 109,
                "total": 180
              },
              "global_facts": {
                "accuracy": 0.6355,
                "correct": 105,
                "total": 166
              },
              "human_aging": {
                "accuracy": 0.6116,
                "correct": 100,
                "total": 164
              },
              "management": {
                "accuracy": 0.6574,
                "correct": 90,
                "total": 137
              },
              "marketing": {
                "accuracy": 0.6851,
                "correct": 96,
                "total": 141
              },
              "medical_genetics": {
                "accuracy": 0.6919,
                "correct": 56,
                "total": 81
              },
              "miscellaneous": {
                "accuracy": 0.6737,
                "correct": 92,
                "total": 137
              },
              "nutrition": {
                "accuracy": 0.6611,
                "correct": 129,
                "total": 196
              },
              "professional_accounting": {
                "accuracy": 0.6934,
                "correct": 113,
                "total": 163
              },
              "professional_medicine": {
                "accuracy": 0.6734,
                "correct": 59,
                "total": 89
              },
              "virology": {
                "accuracy": 0.6915,
                "correct": 116,
                "total": 169
              }
            }
          }
        }
      },
      "few_shot": {
        "overall_accuracy": 0.6907,
        "subjects": {
          "stem": {
            "accuracy": 0.6694,
            "tasks": 57,
            "details": {
              "abstract_algebra": {
                "accuracy": 0.6838,
                "correct": 88,
                "total": 129
              },
              "anatomy": {
                "accuracy": 0.6342,
                "correct": 63,
                "total": 100
              },
              "astronomy": {
                "accuracy": 0.7097,
                "correct": 75,
                "total": 107
              },
              "college_biology": {
                "accuracy": 0.6249,
                "correct": 98,
                "total": 157
              },
              "college_chemistry": {
                "accuracy": 0.7016,
                "correct": 112,
                "total": 160
              },
              "college_computer_science": {
                "accuracy": 0.711,
                "correct": 89,
                "total": 126
              },
              "college_mathematics": {
                "accuracy": 0.685,
                "correct": 127,
                "total": 186
              },
              "college_physics": {
                "accuracy": 0.6866,
                "correct": 60,
                "total": 88
              },
              "computer_security": {
                "accuracy": 0.6214,
                "correct": 89,
                "total": 144
              },
              "conceptual_physics": {
                "accuracy": 0.6996,
                "correct": 57,
                "total": 82
              },
              "electrical_engineering": {
                "accuracy": 0.648,
                "correct": 121,
                "total": 187
              },
              "elementary_mathematics": {
                "accuracy": 0.6719,
                "correct": 100,
                "total": 150
              },
              "high_school_biology": {
                "accuracy": 0.6782,
                "correct": 71,
                "total": 105
              },
              "high_school_chemistry": {
                "accuracy": 0.61,
                "correct": 56,
                "total": 92
              },
              "high_school_computer_science": {
                "accuracy": 0.668,
                "correct": 84,
                "total": 126
              },
              "high_school_mathematics": {
                "accuracy": 0.6658,
                "correct": 94,
                "total": 142
              },
              "high_school_physics": {
                "accuracy": 0.6624,
                "correct": 84,
                "total": 127
              },
              "high_school_statistics": {
                "accuracy": 0.6421,
                "correct": 64,
                "total": 101
              },
              "machine_learning": {
                "accuracy": 0.7099,
                "correct": 106,
                "total": 150
              }
            }
          },
          "humanities": {
            "accuracy": 0.7011,
            "tasks": 52,
            "details": {
              "formal_logic": {
                "accuracy": 0.6923,
                "correct": 119,
                "total": 172
              },
              "high_school_european_history": {
                "accuracy": 0.6985,
                "correct": 94,
                "total": 135
              },
              "high_school_us_history": {
                "accuracy": 0.6776,
                "correct": 106,
                "total": 157
              },
              "high_school_world_history": {
                "accuracy": 0.7534,
                "correct": 79,
                "total": 106
              },
              "international_law": {
                "accuracy": 0.6924,
                "correct": 65,
                "total": 95
              },
              "jurisprudence": {
                "accuracy": 0.7327,
                "correct": 100,
                "total": 137
              },
              "logical_fallacies": {
                "accuracy": 0.7347,
                "correct": 133,
                "total": 182
              },
              "moral_disputes": {
                "accuracy": 0.6888,
                "correct": 98,
                "total": 143
              },
              "moral_scenarios": {
                "accuracy": 0.6441,
                "correct": 101,
                "total": 157
              },
              "philosophy": {
                "accuracy": 0.6444,
                "correct": 57,
                "total": 89
              },
              "prehistory": {
                "accuracy": 0.6679,
                "correct": 100,
                "total": 150
              },
              "professional_law": {
                "accuracy": 0.655,
                "correct": 61,
                "total": 94
              },
              "world_religions": {
                "accuracy": 0.672,
                "correct": 91,
                "total": 136
              }
            }
          },
          "social_sciences": {
            "accuracy": 0.7203,
            "tasks": 48,
            "details": {
              "econometrics": {
                "accuracy": 0.7615,
                "correct": 80,
                "total": 106
              },
              "high_school_geography": {
                "accuracy": 0.6912,
                "correct": 91,
                "total": 133
              },
              "high_school_government_and_politics": {
                "accuracy": 0.78,
                "correct": 82,
                "total": 106
              },
              "high_school_macroeconomics": {
                "accuracy": 0.7408,
                "correct": 114,
                "total": 154
              },
              "high_school_microeconomics": {
                "accuracy": 0.7423,
                "correct": 64,
                "total": 87
              },
              "high_school_psychology": {
                "accuracy": 0.6876,
                "correct": 129,
                "total": 189
              },
              "human_sexuality": {
                "accuracy": 0.698,
                "correct": 103,
                "total": 148
              },
              "professional_psychology": {
                "accuracy": 0.7397,
                "correct": 136,
                "total": 185
              },
              "public_relations": {
                "accuracy": 0.7801,
                "correct": 111,
                "total": 143
              },
              "security_studies": {
                "accuracy": 0.6975,
                "correct": 126,
                "total": 182
              },
              "sociology": {
                "accuracy": 0.6844,
                "correct": 104,
                "total": 153
              },
              "us_foreign_policy": {
                "accuracy": 0.7474,
                "correct": 88,
                "total": 119
              }
            }
          },
          "other": {
            "accuracy": 0.6732,
            "tasks": 43,
            "details": {
              "business_ethics": {
                "accuracy": 0.6714,
                "correct": 107,
                "total": 160
              },
              "clinical_knowledge": {
                "accuracy": 0.6457,
                "correct": 122,
                "total": 189
              },
              "college_medicine": {
                "accuracy": 0.648,
                "correct": 116,
                "total": 180
              },
              "global_facts": {
                "accuracy": 0.6409,
                "correct": 106,
                "total": 166
              },
              "human_aging": {
                "accuracy": 0.6928,
                "correct": 113,
                "total": 164
              },
              "management": {
                "accuracy": 0.6631,
                "correct": 90,
                "total": 137
              },
              "marketing": {
                "accuracy": 0.6675,
                "correct": 94,
                "total": 141
              },
              "medical_genetics": {
                "accuracy": 0.6483,
                "correct": 52,
                "total": 81
              },
              "miscellaneous": {
                "accuracy": 0.7252,
                "correct": 99,
                "total": 137
              },
              "nutrition": {
                "accuracy": 0.6762,
                "correct": 132,
                "total": 196
              },
              "professional_accounting": {
                "accuracy": 0.6215,
                "correct": 101,
                "total": 163
              },
              "professional_medicine": {
                "accuracy": 0.6338,
                "correct": 56,
                "total": 89
              },
              "virology": {
                "accuracy": 0.6146,
                "correct": 103,
                "total": 169
              }
            }
          }
        }
      },
      "delimiter_heavy": {
        "overall_accuracy": 0.6612,
        "subjects": {
          "stem": {
            "accuracy": 0.6255,
            "tasks": 57,
            "details": {
              "abstract_algebra": {
                "accuracy": 0.5716,
                "correct": 73,
                "total": 129
              },
              "anatomy": {
                "accuracy": 0.6571,
                "correct": 65,
                "total": 100
              },
              "astronomy": {
                "accuracy": 0.6762,
                "correct": 72,
                "total": 107
              },
              "college_biology": {
                "accuracy": 0.5709,
                "correct": 89,
                "total": 157
              },
              "college_chemistry": {
                "accuracy": 0.6198,
                "correct": 99,
                "total": 160
              },
              "college_computer_science": {
                "accuracy": 0.6057,
                "correct": 76,
                "total": 126
              },
              "college_mathematics": {
                "accuracy": 0.6787,
                "correct": 126,
                "total": 186
              },
              "college_physics": {
                "accuracy": 0.5675,
                "correct": 49,
                "total": 88
              },
              "computer_security": {
                "accuracy": 0.6045,
                "correct": 87,
                "total": 144
              },
              "conceptual_physics": {
                "accuracy": 0.5985,
                "correct": 49,
                "total": 82
              },
              "electrical_engineering": {
                "accuracy": 0.6489,
                "correct": 121,
                "total": 187
              },
              "elementary_mathematics": {
                "accuracy": 0.6107,
                "correct": 91,
                "total": 150
              },
              "high_school_biology": {
                "accuracy": 0.5977,
                "correct": 62,
                "total": 105
              },
              "high_school_chemistry": {
                "accuracy": 0.6425,
                "correct": 59,
                "total": 92
              },
              "high_school_computer_science": {
                "accuracy": 0.6672,
                "correct": 84,
                "total": 126
              },
              "high_school_mathematics": {
                "accuracy": 0.5741,
                "correct": 81,
                "total": 142
              },
              "high_school_physics": {
                "accuracy": 0.6205,
                "correct": 78,
                "total": 127
              },
              "high_school_statistics": {
                "accuracy": 0.5695,
                "correct": 57,
                "total": 101
              },
              "machine_learning": {
                "accuracy": 0.6848,
                "correct": 102,
                "total": 150
              }
            }
          },
          "humanities": {
            "accuracy": 0.6888,
            "tasks": 52,
            "details": {
              "formal_logic": {
                "accuracy": 0.6977,
                "correct": 120,
                "total": 172
              },
              "high_school_european_history": {
                "accuracy": 0.6903,
                "correct": 93,
                "total": 135
              },
              "high_school_us_history": {
                "accuracy": 0.6907,
                "correct": 108,
                "total": 157
              },
              "high_school_world_history": {
                "accuracy": 0.7332,
                "correct": 77,
                "total": 106
              },
              "international_law": {
                "accuracy": 0.7019,
                "correct": 66,
                "total": 95
              },
              "jurisprudence": {
                "accuracy": 0.7074,
                "correct": 96,
                "total": 137
              },
              "logical_fallacies": {
                "accuracy": 0.6544,
                "correct": 119,
                "total": 182
              },
              "moral_disputes": {
                "accuracy": 0.7249,
                "correct": 103,
                "total": 143
              },
              "moral_scenarios": {
                "accuracy": 0.6479,
                "correct": 101,
                "total": 157
              },
              "philosophy": {
                "accuracy": 0.6843,
                "correct": 60,
                "total": 89
              },
              "prehistory": {
                "accuracy": 0.6572,
                "correct": 98,
                "total": 150
              },
              "professional_law": {
                "accuracy": 0.6387,
                "correct": 60,
                "total": 94
              },
              "world_religions": {
                "accuracy": 0.6713,
                "correct": 91,
                "total": 136
              }
            }
          },
          "social_sciences": {
            "accuracy": 0.697,
            "tasks": 48,
            "details": {
              "econometrics": {
                "accuracy": 0.6672,
                "correct": 70,
                "total": 106
              },
              "high_school_geography": {
                "accuracy": 0.7409,
                "correct": 98,
                "total": 133
              },
              "high_school_government_and_politics": {
                "accuracy": 0.7388,
                "correct": 78,
                "total": 106
              },
              "high_school_macroeconomics": {
                "accuracy": 0.705,
                "correct": 108,
                "total": 154
              },
              "high_school_microeconomics": {
                "accuracy": 0.7353,
                "correct": 63,
                "total": 87
              },
              "high_school_psychology": {
                "accuracy": 0.6434,
                "correct": 121,
                "total": 189
              },
              "human_sexuality": {
                "accuracy": 0.6454,
                "correct": 95,
                "total": 148
              },
              "professional_psychology": {
                "accuracy": 0.7202,
                "correct": 133,
                "total": 185
              },
              "public_relations": {
                "accuracy": 0.6885,
                "correct": 98,
                "total": 143
              },
              "security_studies": {
                "accuracy": 0.654,
                "correct": 119,
                "total": 182
              },
              "sociology": {
                "accuracy": 0.6805,
                "correct": 104,
                "total": 153
              },
              "us_foreign_policy": {
                "accuracy": 0.7048,
                "correct": 83,
                "total": 119
              }
            }
          },
          "other": {
            "accuracy": 0.6353,
            "tasks": 43,
            "details": {
              "business_ethics": {
                "accuracy": 0.5775,
                "correct": 92,
                "total": 160
              },
              "clinical_knowledge": {
                "accuracy": 0.6167,
                "correct": 116,
                "total": 189
              },
              "college_medicine": {
                "accuracy": 0.6716,
                "correct": 120,
                "total": 180
              },
              "global_facts": {
                "accuracy": 0.6164,
                "correct": 102,
                "total": 166
              },
              "human_aging": {
                "accuracy": 0.5942,
                "correct": 97,
                "total": 164
              },
              "management": {
                "accuracy": 0.6825,
                "correct": 93,
                "total": 137
              },
              "marketing": {
                "accuracy": 0.6027,
                "correct": 84,
                "total": 141
              },
              "medical_genetics": {
                "accuracy": 0.6401,
                "correct": 51,
                "total": 81
              },
              "miscellaneous": {
                "accuracy": 0.5872,
                "correct": 80,
                "total": 137
              },
              "nutrition": {
                "accuracy": 0.6248,
                "correct": 122,
                "total": 196
              },
              "professional_accounting": {
                "accuracy": 0.6218,
                "correct": 101,
                "total": 163
              },
              "professional_medicine": {
                "accuracy": 0.6491,
                "correct": 57,
                "total": 89
              },
              "virology": {
                "accuracy": 0.6683,
                "correct": 112,
                "total": 169
              }
            }
          }
        }
      }
    },
    "sensitivity_analysis": {
      "max_variance_subject": "stem",
      "most_sensitive_architecture": "chain_of_thought",
      "robustness_score": 0.85,
      "subject_variances": {
        "stem": 0.001286,
        "humanities": 0.000311,
        "social_sciences": 0.00043,
        "other": 0.001084
      },
      "overall_range": 0.0762
    }
  },
  "analysis": {
    "consistency_delta": 7.62,
    "best_score": 71.81,
    "worst_score": 64.19,
    "robustness_score": 0.85
  }
}